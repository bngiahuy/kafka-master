import kafka from '../configs/kafkaConfig.js';
import redis from '../configs/redisConfig.js';
import 'dotenv/config';
import logMessage from '../utils/logger.js';
import { releaseLock } from '../utils/helper.js'; // ƒê·∫£m b·∫£o import ƒë√∫ng

const consumer = kafka.consumer({
	groupId: 'master-group',
});

// --- Worker Timeout Check --- (Gi·ªØ nguy√™n ho·∫∑c c·∫£i ti·∫øn n·∫øu c·∫ßn)
const checkWorkerStatus = () => {
	console.log('‚è±Ô∏è Starting worker status monitor...');
	const intervalId = setInterval(async () => {
		// L∆∞u intervalId ƒë·ªÉ c√≥ th·ªÉ clear
		try {
			const workers = await redis.hgetall('worker:status');
			const now = Date.now();

			if (Object.keys(workers).length === 0) {
				// console.log("Monitor: No workers registered.");
				return;
			}

			for (const [workerId, status] of Object.entries(workers)) {
				if (status === '1') continue; // B·ªè qua worker ƒëang s·∫µn s√†ng

				const batchInfoRaw = await redis.hget('worker:batchInfo', workerId);
				// console.log(`Monitor check ${workerId}: Status=${status}, BatchInfo=${batchInfoRaw}`);

				if (!batchInfoRaw) {
					console.warn(
						`‚ö†Ô∏è Worker ${workerId} is busy (0) but has no batchInfo. Resetting.`
					);
					await redis.hset('worker:status', workerId, '1'); // Reset v·ªÅ s·∫µn s√†ng
					await releaseLock(workerId); // C·ªë g·∫Øng gi·∫£i ph√≥ng lock ph√≤ng tr∆∞·ªùng h·ª£p c√≤n s√≥t
					continue;
				}

				let batchInfo;
				try {
					batchInfo = JSON.parse(batchInfoRaw);
					if (
						!batchInfo ||
						typeof batchInfo.total !== 'number' ||
						typeof batchInfo.assignedAt !== 'number'
					) {
						console.warn(
							`‚ö†Ô∏è Worker ${workerId} has invalid batchInfo: ${batchInfoRaw}. Resetting.`
						);
						await redis.hset('worker:status', workerId, '1');
						await releaseLock(workerId);
						await redis.hdel('worker:batchInfo', workerId); // X√≥a th√¥ng tin batch l·ªói
						continue;
					}
				} catch (e) {
					console.warn(
						`‚ö†Ô∏è Worker ${workerId} failed to parse batchInfo: ${batchInfoRaw}. Resetting. Error: ${e.message}`
					);
					await redis.hset('worker:status', workerId, '1');
					await releaseLock(workerId);
					await redis.hdel('worker:batchInfo', workerId);
					continue;
				}

				// Timeout d·ª±a tr√™n th·ªùi gian ∆∞·ªõc t√≠nh (v√≠ d·ª•: 1 gi√¢y m·ªói item + 10 gi√¢y c∆° b·∫£n)
				// ƒêi·ªÅu ch·ªânh timeout n√†y cho ph√π h·ª£p v·ªõi th·ª±c t·∫ø x·ª≠ l√Ω c·ªßa b·∫°n
				const estimatedProcessingTime = (batchInfo.total || 0) * 100; // 0.1s/item
				const timeSinceAssigned = now - batchInfo.assignedAt;

				// Ki·ªÉm tra th√™m lastSeen ƒë·ªÉ ch·∫Øc ch·∫Øn worker c√≤n ho·∫°t ƒë·ªông
				const lastSeenRaw = await redis.get(`lastSeen:${workerId}`);
				const lastSeenTime = lastSeenRaw ? parseInt(lastSeenRaw, 10) : 0;
				const timeSinceLastSeen = lastSeenTime ? now - lastSeenTime : Infinity; // N·∫øu ch∆∞a th·∫•y -> coi nh∆∞ v√¥ h·∫°n

				// Coi worker l√† timeout n·∫øu th·ªùi gian k·ªÉ t·ª´ khi g√°n V∆Ø·ª¢T QU√Å th·ªùi gian ∆∞·ªõc t√≠nh
				// V√Ä th·ªùi gian k·ªÉ t·ª´ l·∫ßn cu·ªëi th·∫•y ho·∫°t ƒë·ªông c≈©ng V∆Ø·ª¢T QU√Å timeout (ho·∫∑c ch∆∞a th·∫•y bao gi·ªù)
				if (
					timeSinceAssigned > estimatedProcessingTime &&
					timeSinceLastSeen > estimatedProcessingTime
				) {
					console.warn(
						`‚ö†Ô∏è Worker ${workerId} timeout detected! Assigned ${
							timeSinceAssigned / 1000
						}s ago, last seen ${timeSinceLastSeen / 1000}s ago. Resetting...`
					);
					logMessage(`Worker ${workerId} timeout. Resetting.`);
					// X√≥a th√¥ng tin li√™n quan ƒë·∫øn worker n√†y
					await redis.hdel('worker:status', workerId);
					await redis.hdel('worker:partition', workerId);
					await redis.hdel('worker:batchInfo', workerId);
					await redis.del(`lastSeen:${workerId}`);
					await redis.hdel('worker:processing', batchInfo.batchId); // X√≥a ti·∫øn tr√¨nh c·ªßa batchId n·∫øu c√≥
					await releaseLock(workerId); // Quan tr·ªçng: gi·∫£i ph√≥ng lock
					console.log(`üßπ Cleaned up timeout worker ${workerId}.`);

					// Skip batch id n√†y
				}
			}
		} catch (error) {
			console.error('‚ùå Error in worker status monitor:', error);
		}
	}, 10000); // Ch·∫°y m·ªói 10 gi√¢y

	return () => clearInterval(intervalId); // Tr·∫£ v·ªÅ h√†m ƒë·ªÉ d·ª´ng interval
};

export const runConsumer = async () => {
	let stopMonitoring = null; // Bi·∫øn ƒë·ªÉ gi·ªØ h√†m d·ª´ng monitor
	try {
		await consumer.connect();
		console.log('‚úÖ Consumer connected');

		await consumer.subscribe({
			topics: [
				process.env.KAFKA_TOPIC_NAME_WORKER, // Progress updates
				process.env.KAFKA_TOPIC_NAME_WORKER_FREE, // Worker registration/ready
			],
			fromBeginning: false, // Th∆∞·ªùng kh√¥ng c·∫ßn x·ª≠ l√Ω l·∫°i message c≈© khi consumer kh·ªüi ƒë·ªông l·∫°i
		});
		console.log(
			`üëÇ Consumer subscribed to topics: ${process.env.KAFKA_TOPIC_NAME_WORKER}, ${process.env.KAFKA_TOPIC_NAME_WORKER_FREE}`
		);

		// Kh·ªüi ƒë·ªông worker monitor sau khi connect v√† subscribe th√†nh c√¥ng
		stopMonitoring = checkWorkerStatus();

		await consumer.run({
			eachMessage: async ({ topic, partition, message }) => {
				// console.log(`\nüì© Received message on topic "${topic}", partition ${partition}`);
				let data;
				try {
					data = JSON.parse(message.value.toString());
				} catch (err) {
					console.error(
						`‚ùå Error parsing message value: ${message.value.toString()}`,
						err
					);
					return; // B·ªè qua message kh√¥ng h·ª£p l·ªá
				}

				// --- X·ª≠ l√Ω Worker ƒëƒÉng k√Ω ho·∫∑c b√°o s·∫µn s√†ng ---
				if (topic === process.env.KAFKA_TOPIC_NAME_WORKER_FREE) {
					const { id: workerId, status: workerStatus } = data;
					if (!workerId || !workerStatus) {
						console.warn('‚ö†Ô∏è Received invalid WORKER_FREE message:', data);
						return;
					}
					if (workerStatus !== 'done' && workerStatus !== 'new') {
						console.warn('‚ö†Ô∏è Received invalid WORKER_FREE message:', data);
						return;
					} else if (workerStatus === 'new') {
						const { partitions } = data;
						// ƒêƒÉng k√Ω worker m·ªõi ho·∫∑c worker ƒë√£ xong vi·ªác
						console.log(
							`üÜï New worker ${workerId} registered with partitions:`,
							partitions
						);
						await redis.hset(
							'worker:partition',
							workerId,
							JSON.stringify(partitions)
						);
					} else {
						console.log(`üÜì Worker ${workerId} is free and ready.`);
					}
					// ƒê·∫∑t tr·∫°ng th√°i l√† s·∫µn s√†ng v√† l∆∞u th√¥ng tin partition
					await redis.hset('worker:status', workerId, '1');
					await releaseLock(workerId); // ƒê·∫£m b·∫£o lock ƒë∆∞·ª£c gi·∫£i ph√≥ng khi worker b√°o free
					console.log(
						`   -> Worker ${workerId} status set to 1 (Ready) and lock released.`
					);
				}
				// --- X·ª≠ l√Ω Worker b√°o c√°o ti·∫øn tr√¨nh ---
				else if (topic === process.env.KAFKA_TOPIC_NAME_WORKER) {
					const {
						id: workerId,
						batchId,
						processing,
						total,
						error, // Optional error field from worker
					} = data;

					// --- Validate data ---
					if (
						!workerId ||
						!batchId ||
						processing === undefined ||
						total === undefined
					) {
						console.warn('‚ö†Ô∏è Received invalid WORKER progress message:', data);
						return;
					}
					const processedCount = parseInt(processing, 10);
					const totalCount = parseInt(total, 10);
					if (isNaN(processedCount) || isNaN(totalCount)) {
						console.error(
							`‚ùå Invalid processing/total attributes for batch ${batchId} from worker ${workerId}:`,
							data
						);
						return;
					}

					// --- Update last seen time ---
					await redis.set(`lastSeen:${workerId}`, Date.now(), 'EX', 60 * 5); // C·∫≠p nh·∫≠t v√† t·ª± h·∫øt h·∫°n sau 5 ph√∫t n·∫øu kh√¥ng c√≥ c·∫≠p nh·∫≠t m·ªõi
					// console.log(`   -> Updated lastSeen for ${workerId}`);

					// --- Log progress ---
					logMessage(
						`${workerId} progress ${batchId}: ${processedCount}/${totalCount}`
					);
					// C√≥ th·ªÉ l∆∞u ti·∫øn tr√¨nh v√†o Redis n·∫øu c·∫ßn theo d√µi chi ti·∫øt, nh∆∞ng kh√¥ng b·∫Øt bu·ªôc
					await redis.hset('worker:processing', batchId, processedCount);

					// --- Check for errors reported by worker ---
					if (error) {
						console.error(
							`‚ùå Worker ${workerId} reported error for batch ${batchId}:`,
							error
						);
						logMessage(
							`Worker ${workerId} error on batch ${batchId}: ${error}`
						);
						// Worker b√°o l·ªói -> Coi nh∆∞ xong vi·ªác (l·ªói), reset worker
						await redis.hset('worker:status', workerId, '1'); // ƒê·∫∑t l·∫°i s·∫µn s√†ng
						await releaseLock(workerId); // Gi·∫£i ph√≥ng lock
						await redis.hdel('worker:batchInfo', workerId); // X√≥a th√¥ng tin batch ƒëang l√†m
						console.log(
							`   -> Worker ${workerId} reset to ready (1) due to reported error.`
						);
						// TODO: X·ª≠ l√Ω batchId b·ªã l·ªói (ghi log, ƒë∆∞a v√†o h√†ng ƒë·ª£i l·ªói, ...)
						return; // D·ª´ng x·ª≠ l√Ω message n√†y
					}

					// --- Check if batch is completed ---
					if (processedCount === totalCount) {
						console.log(
							`‚úÖ Worker ${workerId} completed batch ${batchId} (${processedCount}/${totalCount}).`
						);
						logMessage(`Worker ${workerId} completed batch ${batchId}`);

						// Gi·∫£i ph√≥ng worker: ƒê·∫∑t l·∫°i tr·∫°ng th√°i v√† gi·∫£i ph√≥ng lock
						await redis.hset('worker:status', workerId, '1');
						await releaseLock(workerId);
						await redis.hdel('worker:batchInfo', workerId); // X√≥a th√¥ng tin batch ƒë√£ xong
						console.log(
							`   -> Worker ${workerId} status set to 1 (Ready) and lock released.`
						);

						// **QUAN TR·ªåNG: KH√îNG g·ªçi assignBatches() t·ª´ ƒë√¢y**
						// V√≤ng l·∫∑p trong producer s·∫Ω t·ª± ƒë·ªông t√¨m th·∫•y worker n√†y khi n√≥ c·∫ßn.
					} else {
						// Ch·ªâ l√† c·∫≠p nh·∫≠t ti·∫øn tr√¨nh, kh√¥ng l√†m g√¨ th√™m ·ªü consumer
						// console.log(`   -> Worker ${workerId} processing ${batchId}: ${processedCount}/${totalCount}`);
					}
				} else {
					console.warn(`‚ö†Ô∏è Received message on unexpected topic: ${topic}`);
				}
			},
		});

		// Gi·ªØ consumer ch·∫°y
		console.log('‚è≥ Consumer is running. Waiting for messages...');
		// ƒê·ªÉ ngƒÉn h√†m k·∫øt th√∫c ngay l·∫≠p t·ª©c, b·∫°n c√≥ th·ªÉ d√πng m·ªôt promise kh√¥ng bao gi·ªù resolve
		// Ho·∫∑c d·ª±a v√†o vi·ªác process kh√¥ng t·ª± tho√°t
		// await new Promise(() => {});
	} catch (error) {
		console.error('‚ùå Fatal error in consumer:', error);
		if (stopMonitoring) {
			console.log('Stopping worker monitor due to consumer error...');
			stopMonitoring(); // D·ª´ng interval n·∫øu c√≥ l·ªói
		}
		// C√¢n nh·∫Øc vi·ªác c·ªë g·∫Øng k·∫øt n·ªëi l·∫°i ho·∫∑c tho√°t process
		// await consumer.disconnect(); // Th·ª≠ ng·∫Øt k·∫øt n·ªëi
		// process.exit(1);
	}

	// X·ª≠ l√Ω t√≠n hi·ªáu d·ª´ng cho consumer
	const errorTypes = ['unhandledRejection', 'uncaughtException'];
	const signalTraps = ['SIGTERM', 'SIGINT', 'SIGUSR2'];

	errorTypes.forEach((type) => {
		process.on(type, async (err) => {
			try {
				console.log(`üî• Process ${type}: ${err.message}`);
				if (stopMonitoring) stopMonitoring();
				await consumer.disconnect();
				console.log('Consumer disconnected on error.');
				process.exit(1);
			} catch (_) {
				process.exit(1);
			}
		});
	});

	signalTraps.forEach((type) => {
		process.once(type, async () => {
			try {
				console.log(`‚úã Signal ${type} received. Shutting down consumer...`);
				if (stopMonitoring) stopMonitoring();
				await consumer.disconnect();
				console.log('Consumer disconnected gracefully.');
			} finally {
				process.kill(process.pid, type); // ƒê·∫£m b·∫£o process k·∫øt th√∫c ƒë√∫ng c√°ch
			}
		});
	});
};
