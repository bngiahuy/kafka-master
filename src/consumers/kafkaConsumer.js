import kafka from '../configs/kafkaConfig.js';
import redis from '../configs/redisConfig.js';
import 'dotenv/config';
import logMessage from '../utils/logger.js';
import { releaseLock, acquireLock } from '../utils/helper.js'; // ƒê·∫£m b·∫£o import ƒë√∫ng

const consumer = kafka.consumer({
	groupId: 'master-group',
	metadataMaxAge: 60000, // 1 ph√∫t
	allowAutoTopicCreation: true,
	retry: {
		initialRetryTime: 100,
		retries: 8,
	},
	sessionTimeout: 30000,
	heartbeatInterval: 3000,
});

// --- Worker Timeout Check --- (Gi·ªØ nguy√™n ho·∫∑c c·∫£i ti·∫øn n·∫øu c·∫ßn)
const checkWorkerStatus = () => {
	console.log('‚è±Ô∏è Starting worker status monitor...');
	const intervalId = setInterval(async () => {
		// L∆∞u intervalId ƒë·ªÉ c√≥ th·ªÉ clear
		try {
			const workers = await redis.hgetall('worker:status');
			const now = Date.now();

			if (Object.keys(workers).length === 0) {
				// console.log("Monitor: No workers registered.");
				return;
			}

			for (const [workerId, status] of Object.entries(workers)) {
				if (status === '1') continue; // B·ªè qua worker ƒëang s·∫µn s√†ng

				const batchInfoRaw = await redis.hget('worker:batchInfo', workerId);
				// console.log(`Monitor check ${workerId}: Status=${status}, BatchInfo=${batchInfoRaw}`);

				if (!batchInfoRaw) {
					console.warn(
						`‚ö†Ô∏è Worker ${workerId} is busy (0) but has no batchInfo. Resetting.`
					);
					await redis.hset('worker:status', workerId, '1'); // Reset v·ªÅ s·∫µn s√†ng
					await releaseLock(workerId); // C·ªë g·∫Øng gi·∫£i ph√≥ng lock ph√≤ng tr∆∞·ªùng h·ª£p c√≤n s√≥t
					continue;
				}

				let batchInfo;
				try {
					batchInfo = JSON.parse(batchInfoRaw);
					if (
						!batchInfo ||
						typeof batchInfo.total !== 'number' ||
						typeof batchInfo.assignedAt !== 'number'
					) {
						console.warn(
							`‚ö†Ô∏è Worker ${workerId} has invalid batchInfo: ${batchInfoRaw}. Resetting.`
						);
						await redis.hset('worker:status', workerId, '1');
						await releaseLock(workerId);
						await redis.hdel('worker:batchInfo', workerId); // X√≥a th√¥ng tin batch l·ªói
						continue;
					}
				} catch (e) {
					console.warn(
						`‚ö†Ô∏è Worker ${workerId} failed to parse batchInfo: ${batchInfoRaw}. Resetting. Error: ${e.message}`
					);
					await redis.hset('worker:status', workerId, '1');
					await releaseLock(workerId);
					await redis.hdel('worker:batchInfo', workerId);
					continue;
				}

				const estimatedProcessingTime = (batchInfo.total || 0) * 300 + 30000; // 0.1s/item
				const timeSinceAssigned = now - batchInfo.assignedAt;

				// Ki·ªÉm tra th√™m lastSeen ƒë·ªÉ ch·∫Øc ch·∫Øn worker c√≤n ho·∫°t ƒë·ªông
				const lastSeenRaw = await redis.get(`lastSeen:${workerId}`);
				const lastSeenTime = lastSeenRaw ? parseInt(lastSeenRaw, 10) : 0;
				const timeSinceLastSeen = lastSeenTime ? now - lastSeenTime : Infinity; // N·∫øu ch∆∞a th·∫•y -> coi nh∆∞ v√¥ h·∫°n

				// Coi worker l√† timeout n·∫øu th·ªùi gian k·ªÉ t·ª´ khi g√°n V∆Ø·ª¢T QU√Å th·ªùi gian ∆∞·ªõc t√≠nh
				// V√Ä th·ªùi gian k·ªÉ t·ª´ l·∫ßn cu·ªëi th·∫•y ho·∫°t ƒë·ªông c≈©ng V∆Ø·ª¢T QU√Å timeout (ho·∫∑c ch∆∞a th·∫•y bao gi·ªù)
				if (
					timeSinceAssigned > estimatedProcessingTime &&
					timeSinceLastSeen > estimatedProcessingTime
				) {
					console.warn(
						`‚ö†Ô∏è Worker ${workerId} timeout detected! Assigned ${timeSinceAssigned / 1000
						}s ago, last seen ${timeSinceLastSeen / 1000}s ago. Resetting...`
					);
					logMessage(`Worker ${workerId} timeout. Resetting.`);
					// X√≥a th√¥ng tin li√™n quan ƒë·∫øn worker n√†y
					const multi = redis.multi();
					multi.hdel('worker:status', workerId);
					multi.hdel('worker:partition', workerId);
					multi.hdel('worker:batchInfo', workerId);
					multi.del(`lastSeen:${workerId}`);
					multi.hdel('worker:processing', batchInfo.batchId); // X√≥a ti·∫øn tr√¨nh c·ªßa batchId n·∫øu c√≥
					await releaseLock(workerId); // Quan tr·ªçng: gi·∫£i ph√≥ng lock
					console.log(`üßπ Cleaned up timeout worker ${workerId}.`);
					await multi.exec();

					// Skip batch id n√†y
				}
			}
		} catch (error) {
			console.error('‚ùå Error in worker status monitor:', error);
		}
	}, 10000); // Ch·∫°y m·ªói 10 gi√¢y

	return () => clearInterval(intervalId); // Tr·∫£ v·ªÅ h√†m ƒë·ªÉ d·ª´ng interval
};


export const runConsumer = async () => {
	let stopMonitoring = null; // Bi·∫øn ƒë·ªÉ gi·ªØ h√†m d·ª´ng monitor
	try {
		await consumer.connect();
		console.log('‚úÖ Consumer connected');

		await consumer.subscribe({
			topics: [
				process.env.KAFKA_TOPIC_NAME_WORKER_FREE, // Worker registration/ready
				process.env.KAFKA_TOPIC_NAME_WORKER, // Progress updates
			],
			fromBeginning: false, // Th∆∞·ªùng kh√¥ng c·∫ßn x·ª≠ l√Ω l·∫°i message c≈© khi consumer kh·ªüi ƒë·ªông l·∫°i
		});
		console.log(
			`üëÇ Consumer subscribed to topics: ${process.env.KAFKA_TOPIC_NAME_WORKER}, ${process.env.KAFKA_TOPIC_NAME_WORKER_FREE}`
		);


		await consumer.run({
			// ƒê·ªÉ gi·∫£m s·ªë l∆∞·ª£ng message x·ª≠ l√Ω ƒë·ªìng th·ªùi, b·∫°n c√≥ th·ªÉ thay ƒë·ªïi gi√° tr·ªã n√†y
			// partitionsConsumedConcurrently: 10, // ƒêi·ªÅu ch·ªânh d·ª±a tr√™n gi·ªõi h·∫°n API
			eachMessage: async ({ topic, partition, message }) => {
				console.log(`\nüì© Received message on topic "${topic}", partition ${partition}`);
				let data = JSON.parse(message.value.toString());
				// --- X·ª≠ l√Ω Worker ƒëƒÉng k√Ω ho·∫∑c b√°o s·∫µn s√†ng ---
				if (topic === process.env.KAFKA_TOPIC_NAME_WORKER_FREE) {
					const { id: workerId, status: workerStatus } = data;
					if (!workerId || !workerStatus) {
						console.warn('‚ö†Ô∏è Received invalid WORKER_FREE message:', data);
						return;
					}

					// Th√™m acquire lock v·ªõi timeout
					const hasLock = await acquireLock(workerId, 5000);
					if (!hasLock) {
						console.warn(`‚ö†Ô∏è Cannot acquire lock for worker ${workerId}`);
						return;
					}

					try {
						if (workerStatus === 'done') {
							const multi = redis.multi();
							multi.hset('worker:status', workerId, '1');
							await multi.exec();
						} else if (workerStatus === 'new') {
							const { partitions } = data;
							const multi = redis.multi();
							multi.hset('worker:status', workerId, '1');
							multi.hset('worker:partition', workerId, JSON.stringify(partitions));
							multi.hdel('worker:batchInfo', workerId);
							await multi.exec();
						}
					} finally {
						// Lu√¥n release lock trong finally block
						await releaseLock(workerId);
					}
				}
				// --- X·ª≠ l√Ω Worker b√°o c√°o ti·∫øn tr√¨nh ---
				else {
					const {
						id: workerId,
						batchId,
						processing,
						total,
					} = data;

					// --- Validate data ---
					if (
						!workerId ||
						!batchId ||
						processing === undefined ||
						total === undefined
					) {
						console.warn('‚ö†Ô∏è Received invalid WORKER progress message:', data);
						return;
					}
					const processedCount = parseInt(processing, 10);
					const totalCount = parseInt(total, 10);
					if (isNaN(processedCount) || isNaN(totalCount)) {
						console.error(
							`‚ùå Invalid processing/total attributes for batch ${batchId} from worker ${workerId}:`,
							data
						);
						return;
					}

					const multi = redis.multi();
					// --- Update last seen time ---
					multi.set(`lastSeen:${workerId}`, Date.now(), 'EX', 60 * 5); // C·∫≠p nh·∫≠t v√† t·ª± h·∫øt h·∫°n sau 5 ph√∫t n·∫øu kh√¥ng c√≥ c·∫≠p nh·∫≠t m·ªõi
					// console.log(`   -> Updated lastSeen for ${workerId}`);

					// --- Log progress ---
					console.log(
						`${workerId} progress ${batchId}: ${processedCount}/${totalCount}`
					);
					logMessage(
						`${workerId} progress ${batchId}: ${processedCount}/${totalCount}`
					);
					// C√≥ th·ªÉ l∆∞u ti·∫øn tr√¨nh v√†o Redis n·∫øu c·∫ßn theo d√µi chi ti·∫øt, nh∆∞ng kh√¥ng b·∫Øt bu·ªôc
					multi.hset('worker:processing', batchId, processedCount);
					// --- Check if batch is completed ---
					if (processedCount === totalCount) {
						console.log(
							`‚úÖ Worker ${workerId} completed batch ${batchId} (${processedCount}/${totalCount}).`
						);
						// logMessage(`Worker ${workerId} completed batch ${batchId}`);
						multi.hdel('worker:batchInfo', workerId); // X√≥a th√¥ng tin batch ƒë√£ xong
						console.log(
							`   -> Worker ${workerId} status set to 1 (Ready) and lock released.`
						);


					}
					await multi.exec();
				}
			},
		});
		stopMonitoring = checkWorkerStatus();


		// Gi·ªØ consumer ch·∫°y
		console.log('‚è≥ Consumer is running. Waiting for messages...');
		// ƒê·ªÉ ngƒÉn h√†m k·∫øt th√∫c ngay l·∫≠p t·ª©c, b·∫°n c√≥ th·ªÉ d√πng m·ªôt promise kh√¥ng bao gi·ªù resolve
		// Ho·∫∑c d·ª±a v√†o vi·ªác process kh√¥ng t·ª± tho√°t
		// await new Promise(() => {});
	} catch (error) {
		console.error('‚ùå Fatal error in consumer:', error);
		if (stopMonitoring) {
			console.log('Stopping worker monitor due to consumer error...');
			stopMonitoring(); // D·ª´ng interval n·∫øu c√≥ l·ªói
		}
		// C√¢n nh·∫Øc vi·ªác c·ªë g·∫Øng k·∫øt n·ªëi l·∫°i ho·∫∑c tho√°t process
		// await consumer.disconnect(); // Th·ª≠ ng·∫Øt k·∫øt n·ªëi
		// process.exit(1);
	}

	// X·ª≠ l√Ω t√≠n hi·ªáu d·ª´ng cho consumer
	const errorTypes = ['unhandledRejection', 'uncaughtException'];
	const signalTraps = ['SIGTERM', 'SIGINT', 'SIGUSR2'];

	errorTypes.forEach((type) => {
		process.on(type, async (err) => {
			try {
				console.log(`üî• Process ${type}: ${err.message}`);
				if (stopMonitoring) stopMonitoring();
				await consumer.disconnect();
				console.log('Consumer disconnected on error.');
				process.exit(1);
			} catch (_) {
				process.exit(1);
			}
		});
	});

	signalTraps.forEach((type) => {
		process.once(type, async () => {
			try {
				console.log(`‚úã Signal ${type} received. Shutting down consumer...`);
				if (stopMonitoring) stopMonitoring();
				await consumer.disconnect();
				console.log('Consumer disconnected gracefully.');
			} finally {
				process.kill(process.pid, type); // ƒê·∫£m b·∫£o process k·∫øt th√∫c ƒë√∫ng c√°ch
			}
		});
	});
};
